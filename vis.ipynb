{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import get_test_pipeline_cfg\n",
    "\n",
    "import mmcv\n",
    "from mmcv.transforms import Compose\n",
    "from mmengine.visualization import Visualizer\n",
    "\n",
    "from mmdet.visualization import local_visualizer as lv\n",
    "from mmdet.evaluation.functional import get_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faster rcnn 第一阶段产生的proposal box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/faster-rcnn_r50_fpn_1x_voc0712.py\"\n",
    "checkpoint_file = \"ckpts/faster_rcnn_epoch_4.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"test_image/OOD4.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = init_detector(config_file, checkpoint_file, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(model, image):\n",
    "    cfg = model.cfg.copy()\n",
    "    test_pipeline = get_test_pipeline_cfg(cfg)\n",
    "    if isinstance(image, np.ndarray):\n",
    "        test_pipeline[0].type = \"mmdet.LoadImageFromNDArray\"\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    data = test_pipeline(dict(img_path=image))\n",
    "    data[\"inputs\"] = [data[\"inputs\"]]\n",
    "    data[\"data_samples\"] = [data[\"data_samples\"]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(model, image_file)\n",
    "with torch.no_grad():\n",
    "    feature = model.extract_feat(data[\"inputs\"][0].unsqueeze(0).float().cuda())\n",
    "    (cls_scores, bbox_shift) = model.rpn_head.forward(feature)\n",
    "    anchor_generator = model.rpn_head.prior_generator\n",
    "    feature_map_size = [feature[i].size()[-2:] for i in range(len(feature))]\n",
    "    anchors = anchor_generator.grid_priors(feature_map_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_scores = [cls_score.squeeze() for cls_score in cls_scores]\n",
    "bbox_shift = [shift.squeeze() for shift in bbox_shift]\n",
    "\n",
    "boxes = model.rpn_head._predict_by_feat_single(\n",
    "    cls_score_list = cls_scores,\n",
    "    bbox_pred_list = bbox_shift,\n",
    "    score_factor_list = None,\n",
    "    mlvl_priors = anchors,\n",
    "    img_meta = data[\"data_samples\"][0].to_dict(),\n",
    "    cfg = None,\n",
    "    rescale = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes.bboxes[0:5]\n",
    "visualizer = Visualizer(image=mmcv.imread(image_file,channel_order='rgb'));\n",
    "visualizer.draw_bboxes(boxes.bboxes[0:100]); #[0:100]\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faster rcnn 测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_detector(model, image_file)\n",
    "\n",
    "visualizer = lv.DetLocalVisualizer()\n",
    "class_names = get_classes(\"voc\")\n",
    "visualizer.dataset_meta[\"classes\"] = class_names\n",
    "visualizer.dataset_meta[\"palette\"] = [\n",
    "    (106, 0, 228),\n",
    "    (119, 11, 32),\n",
    "    (165, 42, 42),\n",
    "    (0, 0, 192),\n",
    "    (197, 226, 255),\n",
    "    (0, 60, 100),\n",
    "    (0, 0, 142),\n",
    "    (255, 77, 255),\n",
    "    (153, 69, 1),\n",
    "    (120, 166, 157),\n",
    "    (0, 182, 199),\n",
    "    (0, 226, 252),\n",
    "    (182, 182, 255),\n",
    "    (0, 0, 230),\n",
    "    (220, 20, 60),\n",
    "    (163, 255, 0),\n",
    "    (0, 82, 0),\n",
    "    (3, 95, 161),\n",
    "    (0, 80, 100),\n",
    "    (183, 130, 88),\n",
    "]\n",
    "visualizer.add_datasample(\n",
    "            \"Plot1\",\n",
    "            mmcv.imread(image_file,channel_order='rgb'),\n",
    "            result,\n",
    "            draw_gt= False,\n",
    "            draw_pred = True,\n",
    "            show = True,\n",
    "            wait_time = 0,\n",
    "            out_file = None, #image_file.replace('test_image', 'test_image/out').replace('.jpg', '_pred.jpg'),\n",
    "            pred_score_thr = 0.3,\n",
    "            step = 0);\n",
    "\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolov3 测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"config/yolov3_d53_8xb8-ms-608-273e_1x_voc0712.py\"\n",
    "checkpoint_file = \"ckpts/yolov3_epoch_6.pth\"\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = init_detector(config_file, checkpoint_file, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"test_image/OOD1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = inference_detector(model, image_file)\n",
    "visualizer = lv.DetLocalVisualizer()\n",
    "class_names = get_classes(\"voc\")\n",
    "visualizer.dataset_meta[\"classes\"] = class_names\n",
    "visualizer.dataset_meta[\"palette\"] = [\n",
    "    (106, 0, 228),\n",
    "    (119, 11, 32),\n",
    "    (165, 42, 42),\n",
    "    (0, 0, 192),\n",
    "    (197, 226, 255),\n",
    "    (0, 60, 100),\n",
    "    (0, 0, 142),\n",
    "    (255, 77, 255),\n",
    "    (153, 69, 1),\n",
    "    (120, 166, 157),\n",
    "    (0, 182, 199),\n",
    "    (0, 226, 252),\n",
    "    (182, 182, 255),\n",
    "    (0, 0, 230),\n",
    "    (220, 20, 60),\n",
    "    (163, 255, 0),\n",
    "    (0, 82, 0),\n",
    "    (3, 95, 161),\n",
    "    (0, 80, 100),\n",
    "    (183, 130, 88),\n",
    "]\n",
    "visualizer.add_datasample(\n",
    "            \"Plot1\",\n",
    "            mmcv.imread(image_file,channel_order='rgb'),\n",
    "            result,\n",
    "            draw_gt= False,\n",
    "            draw_pred = True,\n",
    "            show = True,\n",
    "            wait_time = 0,\n",
    "            out_file = None,\n",
    "            pred_score_thr = 0.3,\n",
    "            step = 0);\n",
    "visualizer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
